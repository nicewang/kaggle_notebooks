{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from huggingface_hub import login\n\nhuggingface_key = \"xxx...xxx\"\nlogin(huggingface_key)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-07T03:30:57.137950Z","iopub.execute_input":"2024-10-07T03:30:57.138637Z","iopub.status.idle":"2024-10-07T03:30:57.696192Z","shell.execute_reply.started":"2024-10-07T03:30:57.138587Z","shell.execute_reply":"2024-10-07T03:30:57.695237Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: fineGrained).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install flash-attn --no-build-isolation","metadata":{"execution":{"iopub.status.busy":"2024-10-07T03:31:19.210068Z","iopub.execute_input":"2024-10-07T03:31:19.210949Z","iopub.status.idle":"2024-10-07T03:31:48.656008Z","shell.execute_reply.started":"2024-10-07T03:31:19.210906Z","shell.execute_reply":"2024-10-07T03:31:48.654848Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting flash-attn\n  Downloading flash_attn-2.6.3.tar.gz (2.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from flash-attn) (2.4.0)\nCollecting einops (from flash-attn)\n  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (2024.6.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->flash-attn) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->flash-attn) (1.3.0)\nDownloading einops-0.8.0-py3-none-any.whl (43 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: flash-attn\n  Building wheel for flash-attn (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for flash-attn: filename=flash_attn-2.6.3-cp310-cp310-linux_x86_64.whl size=187315346 sha256=6ebfbdcbdd164f80278a954d29a1bc9d620130264215f0fb93374a6ab4e0a283\n  Stored in directory: /root/.cache/pip/wheels/7e/e3/c3/89c7a2f3c4adc07cd1c675f8bb7b9ad4d18f64a72bccdfe826\nSuccessfully built flash-attn\nInstalling collected packages: einops, flash-attn\nSuccessfully installed einops-0.8.0 flash-attn-2.6.3\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\n\nif torch.cuda.is_available():\n    print(\"GPU is available\")\nelse:\n    print(\"GPU is not available\")","metadata":{"execution":{"iopub.status.busy":"2024-10-07T03:32:39.745439Z","iopub.execute_input":"2024-10-07T03:32:39.745835Z","iopub.status.idle":"2024-10-07T03:32:41.458397Z","shell.execute_reply.started":"2024-10-07T03:32:39.745795Z","shell.execute_reply":"2024-10-07T03:32:41.457452Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"GPU is available\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\nfrom tqdm import tqdm\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    \"mistralai/Mixtral-8x7B-v0.1\", \n    torch_dtype=torch.float16, \n    device_map=\"auto\",\n    offload_folder=\"offload\"\n)\n\ntokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mixtral-8x7B-v0.1\")\n\nprompt = \"My favourite condiment is\"\nmodel_inputs = tokenizer([prompt], return_tensors=\"pt\").to(device)","metadata":{"execution":{"iopub.status.busy":"2024-10-07T03:35:56.880746Z","iopub.execute_input":"2024-10-07T03:35:56.881265Z","iopub.status.idle":"2024-10-07T03:48:02.386837Z","shell.execute_reply.started":"2024-10-07T03:35:56.881228Z","shell.execute_reply":"2024-10-07T03:48:02.385821Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/720 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3197d10e63ae4fa6bf79257289883c42"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/92.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a50e2d0194ea417c8b471e863b9cdafb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/19 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"55884ffe8aad4f0f8ce195a377682089"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00019.safetensors:   0%|          | 0.00/4.89G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce097e9e4d6245bb8d362e6e821e9250"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00019.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c3723fae206843149bdc84db0b3d5063"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00019.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"05ed090e4d6847f2b0fa811bd58b2a8c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00004-of-00019.safetensors:   0%|          | 0.00/4.90G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e41c8c6fa42e45a582cf3b7a39f465a2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00005-of-00019.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"852f8b57a4044c79bbfa658d2ecd91dd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00006-of-00019.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92311e81b87f43638d0a15c219220894"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00007-of-00019.safetensors:   0%|          | 0.00/4.90G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d533c25e79384a6b94f1736ec3b8206b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00008-of-00019.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b07f1e19b0864ddbba252aa1d6f22c37"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00009-of-00019.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85eed9ad375e45f0ac7e1eaa8d70d6f1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00010-of-00019.safetensors:   0%|          | 0.00/4.90G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f5e6b1995b644129fdc64b1d8865c68"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00011-of-00019.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"44161c00f7104290926fdbdfceaf36f8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00012-of-00019.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a111d631f9b4cac8510e6c1fbc479e0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00013-of-00019.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dfa37841edaf4bb18426dd3456975907"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00014-of-00019.safetensors:   0%|          | 0.00/4.90G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee4c674c18be495a8dc9cad887343177"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00015-of-00019.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b96a74850d364ca6b80d4129236e60f5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00016-of-00019.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41d4d89df567473587a2fb0861fac25d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00017-of-00019.safetensors:   0%|          | 0.00/4.90G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e7e26dc4b24c40deae6123ed3654f375"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00018-of-00019.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"46a52cccbe9c4db088485e0b253e5453"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00019-of-00019.safetensors:   0%|          | 0.00/4.22G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2770b4a4bc59408b8c34278c472f871c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/19 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4b06615c7ef42d6b4b25115f9985739"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d7dec0da0b92411689fb6e4f2288ecdf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/967 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"59e6504f15574faa940334a66ff4492f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"19af04b60f81410bbbf34bcfe82f1f08"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a7cbf9df7e1c46b6ac2d84c0ead56fca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/72.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b90e9db5bbe84298a9e5a51442080944"}},"metadata":{}}]},{"cell_type":"markdown","source":"## Generate 5 new tokens","metadata":{}},{"cell_type":"code","source":"output_sequences = []\nfor i in tqdm(range(4)):\n    with torch.amp.autocast('cuda'):\n        generated_ids = model.generate(**model_inputs, max_new_tokens=5, do_sample=True)\n        output_sequences.append(generated_ids)","metadata":{"execution":{"iopub.status.busy":"2024-10-07T04:12:51.675202Z","iopub.execute_input":"2024-10-07T04:12:51.675614Z","iopub.status.idle":"2024-10-07T05:30:10.437792Z","shell.execute_reply.started":"2024-10-07T04:12:51.675577Z","shell.execute_reply":"2024-10-07T05:30:10.436928Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"  0%|          | 0/4 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 25%|██▌       | 1/4 [18:28<55:24, 1108.11s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 50%|█████     | 2/4 [38:10<38:24, 1152.04s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 75%|███████▌  | 3/4 [57:51<19:25, 1165.27s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n100%|██████████| 4/4 [1:17:18<00:00, 1159.69s/it]\n","output_type":"stream"}]},{"cell_type":"code","source":"output_sequences = torch.cat(output_sequences, dim=1)\n\ndecoded_output = tokenizer.batch_decode(output_sequences, skip_special_tokens=True)[0]\nprint(decoded_output)","metadata":{"execution":{"iopub.status.busy":"2024-10-07T05:34:09.745507Z","iopub.execute_input":"2024-10-07T05:34:09.746124Z","iopub.status.idle":"2024-10-07T05:34:09.750637Z","shell.execute_reply.started":"2024-10-07T05:34:09.746087Z","shell.execute_reply":"2024-10-07T05:34:09.749668Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"My favourite condiment is the one I cannot pron My favourite condiment is a toss up between must My favourite condiment is Sriracha hot My favourite condiment is hot sauce.  I\n","output_type":"stream"}]}]}